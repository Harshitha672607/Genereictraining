name: model training v10
inputs:
  - {name: X_data, type: Dataset, description: "Parquet file for features (DataFrame)"}
  - {name: y_data, type: Dataset, description: "Parquet file for target (Series or single-column DataFrame) - already encoded"}
  - {name: model_type, type: String, description: "classification or regression", optional: true, default: "classification"}
  - {name: enbalance, type: String, description: "true/false for class imbalance handling (classification only)", optional: true, default: "true"}
  - {name: target_column, type: String, description: "Optional. Column name inside y parquet if it has multiple columns", optional: true, default: ""}
  - {name: preprocess_metadata, type: Data, description: "Optional metadata from preprocessing (for reference)", optional: true}
  - {name: model_name, type: String, description: "Model to train: linear | logistic | polynomial | random_forest", optional: true, default: "logistic"}
  - {name: use_scaler, type: String, description: "true/false. If true, apply StandardScaler (recommended for linear models)", optional: true, default: "true"}
  - {name: fit_intercept, type: String, description: "Whether to calculate intercept for linear/logistic regression", optional: true, default: "true"}
  - {name: regularization, type: String, description: "Regularization type: none | l1 | l2 | elasticnet", optional: true, default: "none"}
  - {name: C_value, type: Float, description: "Inverse of regularization strength (smaller values = stronger regularization)", optional: true, default: "1.0"}
  - {name: poly_degree, type: Integer, description: "Degree for polynomial features (for polynomial regression only)", optional: true, default: "2"}
  - {name: solver, type: String, description: "Solver for logistic regression: lbfgs | liblinear | newton-cg | sag | saga", optional: true, default: "lbfgs"}
  - {name: max_iter, type: Integer, description: "Maximum iterations for optimization", optional: true, default: "100"}
  - {name: random_state, type: Integer, description: "Random seed for reproducibility", optional: true, default: "48"}
  - {name: n_estimators, type: Integer, description: "Number of trees in random forest", optional: true, default: "100"}
  - {name: max_depth, type: Integer, description: "Maximum depth of trees in random forest (0 for unlimited)", optional: true, default: "0"}
  - {name: min_samples_split, type: Integer, description: "Minimum samples required to split a node", optional: true, default: "2"}
  - {name: min_samples_leaf, type: Integer, description: "Minimum samples required at a leaf node", optional: true, default: "1"}
  - {name: max_features, type: String, description: "Number of features to consider for best split: auto | sqrt | log2 | number or percentage", optional: true, default: "auto"}
  - {name: bootstrap, type: String, description: "Whether to use bootstrap samples when building trees", optional: true, default: "true"}
  - {name: oob_score, type: String, description: "Whether to calculate out-of-bag score (random forest)", optional: true, default: "false"}

outputs:
  - {name: model_pickle, type: Model, description: "Pickled trained model (.pkl)"}
  - {name: metrics_json, type: Data, description: "Training metrics JSON"}
  - {name: model_config, type: Data, description: "Model configuration JSON (hyperparameters & metadata)"}

implementation:
  container:
    image: kumar2004/ml-base:v1
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, sys, json, traceback
        import pandas as pd, numpy as np, joblib
        from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures
        from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet
        from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score, mean_squared_error, mean_absolute_error, log_loss, roc_auc_score
        from sklearn.utils.class_weight import compute_sample_weight
        from sklearn.model_selection import cross_val_score
        from sklearn.pipeline import Pipeline

        def ensure_dir_for(p):
            d = os.path.dirname(p)
            if d and not os.path.exists(d):
                os.makedirs(d, exist_ok=True)

        def bool_from_str(s):
            return str(s).strip().lower() in ("1","true","t","yes","y")

        def load_parquet_df(path):
            return pd.read_csv(path)

        def try_load_metadata(path):
            if not path or not os.path.exists(path):
                return None
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception:
                pass
            try:
                return joblib.load(path)
            except Exception:
                return None

        def parse_max_features(max_features_str, n_features):
            max_features_str = str(max_features_str).strip().lower()
            
            if max_features_str == "auto":
                return "sqrt"
            elif max_features_str == "sqrt":
                return "sqrt"
            elif max_features_str == "log2":
                return "log2"
            elif max_features_str.endswith("%"):
                try:
                    percentage = float(max_features_str[:-1]) / 100.0
                    return max(1, int(n_features * percentage))
                except:
                    return "sqrt"
            else:
                try:
                    val = int(max_features_str)
                    return max(1, min(val, n_features))
                except:
                    try:
                        val = float(max_features_str)
                        return max(1, int(n_features * val))
                    except:
                        return "sqrt"

        def determine_task(y, user_specified_task, model_name):
            user_task = str(user_specified_task).strip().lower()
            
            # If user explicitly specified task, use that
            if user_task in ["classification", "regression"]:
                print(f"[INFO] Using user-specified task: {user_task}")
                return user_task
            
            # If model is logistic, force classification (even if data looks numeric)
            if model_name == "logistic":
                print(f"[INFO] Model 'logistic' detected, forcing classification task")
                return "classification"
            
            # If model is linear, polynomial, or random_forest, need to analyze data
            # First try to detect if this is classification data
            y_series = pd.Series(y).astype(str).str.strip()
            unique_values = y_series.nunique()
            
            # If few unique values, could be classification
            if unique_values <= 10:
                # Check if values look like classes (strings or integers)
                try:
                    # Try to convert to numeric and see if they're integers
                    y_numeric = pd.to_numeric(y_series, errors='coerce')
                    if y_numeric.notna().all():
                        # All values are numeric
                        if y_numeric.apply(float.is_integer).all() and unique_values <= 10:
                            print(f"[INFO] Detected classification (integer classes: {sorted(y_numeric.unique().tolist())})")
                            return "classification"
                except:
                    pass
                
                # Check for string categories
                if unique_values <= 10:
                    print(f"[INFO] Detected classification (unique string values: {sorted(y_series.unique().tolist())})")
                    return "classification"
            
            # Default to regression
            print(f"[INFO] Detected regression (continuous target)")
            return "regression"

        ap = argparse.ArgumentParser()
        ap.add_argument('--X_data', type=str, required=True)
        ap.add_argument('--y_data', type=str, required=True)
        ap.add_argument('--model_type', type=str, default="classification")
        ap.add_argument('--enbalance', type=str, default="true")
        ap.add_argument('--target_column', type=str, default="")
        ap.add_argument('--preprocess_metadata', type=str, default="")
        ap.add_argument('--model_name', type=str, default="logistic")
        ap.add_argument('--use_scaler', type=str, default="true")
        ap.add_argument('--fit_intercept', type=str, default="true")
        ap.add_argument('--regularization', type=str, default="none")
        ap.add_argument('--C_value', type=float, default=1.0)
        ap.add_argument('--poly_degree', type=int, default=2)
        ap.add_argument('--solver', type=str, default="lbfgs")
        ap.add_argument('--max_iter', type=int, default=100)
        ap.add_argument('--random_state', type=int, default=48)
        ap.add_argument('--n_estimators', type=int, default=100)
        ap.add_argument('--max_depth', type=int, default=0)
        ap.add_argument('--min_samples_split', type=int, default=2)
        ap.add_argument('--min_samples_leaf', type=int, default=1)
        ap.add_argument('--max_features', type=str, default="auto")
        ap.add_argument('--bootstrap', type=str, default="true")
        ap.add_argument('--oob_score', type=str, default="false")
        ap.add_argument('--model_pickle', type=str, required=True)
        ap.add_argument('--metrics_json', type=str, required=True)
        ap.add_argument('--model_config', type=str, required=True)
        args = ap.parse_args()

        try:
            print("="*80)
            print("MODEL TRAINING STARTED (linear | logistic | polynomial | random_forest)")
            print("="*80)

            X = load_parquet_df(args.X_data)
            print(f"[INFO] X shape: {X.shape}")
            print("[INFO] First 5 rows of X:")
            print(X.head())

            y_df = load_parquet_df(args.y_data)
            if isinstance(y_df, pd.DataFrame):
                if y_df.shape[1] == 1 and not args.target_column:
                    y = y_df.iloc[:, 0].copy()
                    print(f"[INFO] Auto-detected single column: {y_df.columns[0]}")
                else:
                    col = args.target_column.strip()
                    if not col:
                        raise ValueError(f"y parquet has {y_df.shape[1]} columns. Provide --target_column. Available: {list(y_df.columns)}")
                    y = y_df[col].copy()
            else:
                y = pd.Series(y_df).copy()

            # align lengths/indices if mismatch
            if len(X) != len(y):
                print(f"[WARN] Length mismatch: X={len(X)}, y={len(y)}")
                common_idx = X.index.intersection(y.index)
                if len(common_idx) > 0:
                    X = X.loc[common_idx].sort_index()
                    y = y.loc[common_idx].sort_index()
                else:
                    m = min(len(X), len(y))
                    X = X.reset_index(drop=True).iloc[:m, :].copy()
                    y = y.reset_index(drop=True).iloc[:m].copy()

            # Determine task based on combination of user input and data
            model_name = args.model_name.strip().lower()
            task = determine_task(y, args.model_type, model_name)
            
            print("===== TARGET VARIABLE INFO =====")
            if task == "classification":
                print("Classification task - target distribution:")
                print(y.value_counts(dropna=False).to_string())
                print(f"Unique values: {y.nunique()}")
                print("Distribution percentages:")
                print((y.value_counts(dropna=False, normalize=True) * 100).round(2).to_string())
                
                # For classification with numeric target that should be classes (like 0/1)
                if pd.api.types.is_numeric_dtype(y):
                    print(f"[INFO] Numeric target for classification - unique values: {sorted(y.unique().tolist())}")
            else:
                print("Regression task - converting target to numeric...")
                y_numeric_check = pd.to_numeric(y, errors="coerce")
                valid_numeric = y_numeric_check.notna()
                
                if valid_numeric.sum() == 0:
                    print("[ERROR] Target variable contains no valid numeric values")
                    print(f"[ERROR] Sample values from target: {y.head(10).tolist()}")
                    raise ValueError("Target variable contains no valid numeric values for regression task")
                
                if not valid_numeric.all():
                    invalid_count = int((~valid_numeric).sum())
                    print(f"[WARN] Found {invalid_count} non-numeric values in target")
                    print(f"[WARN] Sample of non-numeric values: {y[~valid_numeric].head(5).tolist()}")
                
                y_valid = y_numeric_check[valid_numeric]
                min_val = float(y_valid.min())
                max_val = float(y_valid.max())
                mean_val = float(y_valid.mean())
                std_val = float(y_valid.std())
                
                print("Target statistics (numeric values only):")
                print(f"Min: {min_val:.4f}")
                print(f"Max: {max_val:.4f}")
                print(f"Mean: {mean_val:.4f}")
                print(f"Std: {std_val:.4f}")
                print(f"Valid numeric values: {int(valid_numeric.sum())}")
                print(f"Missing/invalid values: {int((~valid_numeric).sum())}")

            metrics = {"task": task, "samples": int(len(y)), "features": int(X.shape[1])}
            model_obj = None

            # prepare model config skeleton
            model_config = {
                "model_name": model_name,
                "task": task,
                "random_state": int(args.random_state),
                "params": {}
            }

            if task == "classification":
                print(f"[INFO] Classification task with model: {model_name}")
                
                # Prepare target for classification
                meta = try_load_metadata(args.preprocess_metadata)
                label_mapping = meta.get("label_mapping") if meta else None

                # Convert target to appropriate format
                y_series = pd.Series(y).astype(str).str.strip()
                
                # Try to preserve original values if they look like integers
                try:
                    y_int = pd.to_numeric(y_series, errors='coerce')
                    if y_int.notna().all() and y_int.apply(float.is_integer).all():
                        y_prepared = y_int.astype(int)
                        map_info = {
                            "mode": "integer_classes", 
                            "classes": sorted(y_prepared.unique().tolist()),
                            "label_mapping_reference": label_mapping
                        }
                        print(f"[INFO] Using integer classes: {sorted(y_prepared.unique().tolist())}")
                    else:
                        # Use label encoder for string classes
                        le = LabelEncoder()
                        y_prepared = pd.Series(le.fit_transform(y_series), index=y.index)
                        map_info = {
                            "mode": "label_encoder", 
                            "classes": le.classes_.tolist(),
                            "mapping": dict(zip(le.classes_, le.transform(le.classes_)))
                        }
                        print(f"[INFO] Encoded classes: {dict(zip(le.classes_, le.transform(le.classes_)))}")
                except Exception as e:
                    print(f"[WARN] Error in class encoding: {e}")
                    # Fallback to label encoder
                    le = LabelEncoder()
                    y_prepared = pd.Series(le.fit_transform(y_series), index=y.index)
                    map_info = {
                        "mode": "label_encoder_fallback", 
                        "classes": le.classes_.tolist()
                    }

                valid_mask = y_prepared.notna()
                if not valid_mask.all():
                    dropped = int((~valid_mask).sum())
                    X = X.loc[valid_mask].reset_index(drop=True)
                    y_prepared = y_prepared[valid_mask].reset_index(drop=True)
                    print(f"[WARN] Dropped {dropped} invalid rows")

                if model_name == "logistic":
                    print(f"[INFO] Training Logistic Regression")
                    print(f"  - solver: {args.solver}")
                    print(f"  - C: {args.C_value}")
                    print(f"  - regularization: {args.regularization}")
                    print(f"  - fit_intercept: {args.fit_intercept}")
                    print(f"  - max_iter: {args.max_iter}")
                    print(f"  - use_scaler: {args.use_scaler}")
                    print(f"  - class_balance: {args.enbalance}")
                    
                    # Determine class weight
                    class_weight_val = 'balanced' if bool_from_str(args.enbalance) else None
                    
                    # Handle regularization
                    penalty_map = {
                        'none': None,
                        'l1': 'l1',
                        'l2': 'l2',
                        'elasticnet': 'elasticnet'
                    }
                    penalty = penalty_map.get(args.regularization, None)
                    
                    # Adjust solver based on penalty
                    solver = args.solver
                    if penalty == 'l1':
                        if solver not in ['liblinear', 'saga']:
                            solver = 'liblinear'
                            print(f"[INFO] Changed solver to {solver} for L1 regularization")
                    elif penalty == 'elasticnet':
                        if solver != 'saga':
                            solver = 'saga'
                            print(f"[INFO] Changed solver to {solver} for elasticnet regularization")
                    
                    # Create logistic regression model
                    lr_model = LogisticRegression(
                        penalty=penalty,
                        C=float(args.C_value),
                        fit_intercept=bool_from_str(args.fit_intercept),
                        class_weight=class_weight_val,
                        solver=solver,
                        max_iter=int(args.max_iter),
                        random_state=int(args.random_state)
                    )
                    
                    # Scale if requested
                    if bool_from_str(args.use_scaler):
                        clf = Pipeline([('scaler', StandardScaler()), ('est', lr_model)])
                    else:
                        clf = lr_model
                        
                    model_config["params"] = {
                        "solver": solver,
                        "C": float(args.C_value),
                        "penalty": penalty,
                        "fit_intercept": bool_from_str(args.fit_intercept),
                        "max_iter": int(args.max_iter),
                        "class_weight": class_weight_val,
                        "use_scaler": bool_from_str(args.use_scaler)
                    }

                elif model_name == "random_forest":
                    print(f"[INFO] Training Random Forest Classifier")
                    print(f"  - n_estimators: {args.n_estimators}")
                    print(f"  - max_depth: {args.max_depth} (0 = unlimited)")
                    print(f"  - min_samples_split: {args.min_samples_split}")
                    print(f"  - min_samples_leaf: {args.min_samples_leaf}")
                    print(f"  - max_features: {args.max_features}")
                    print(f"  - bootstrap: {args.bootstrap}")
                    print(f"  - oob_score: {args.oob_score}")
                    print(f"  - class_balance: {args.enbalance}")
                    
                    # Determine class weight
                    class_weight_val = 'balanced' if bool_from_str(args.enbalance) else None
                    
                    # Parse max_features
                    max_features_parsed = parse_max_features(args.max_features, X.shape[1])
                    
                    # Create Random Forest model
                    rf_model = RandomForestClassifier(
                        n_estimators=int(args.n_estimators),
                        max_depth=None if int(args.max_depth) <= 0 else int(args.max_depth),
                        min_samples_split=int(args.min_samples_split),
                        min_samples_leaf=int(args.min_samples_leaf),
                        max_features=max_features_parsed,
                        bootstrap=bool_from_str(args.bootstrap),
                        oob_score=bool_from_str(args.oob_score),
                        class_weight=class_weight_val,
                        random_state=int(args.random_state),
                        n_jobs=-1
                    )
                    
                    clf = rf_model
                    model_config["params"] = {
                        "n_estimators": int(args.n_estimators),
                        "max_depth": None if int(args.max_depth) <= 0 else int(args.max_depth),
                        "min_samples_split": int(args.min_samples_split),
                        "min_samples_leaf": int(args.min_samples_leaf),
                        "max_features": max_features_parsed,
                        "bootstrap": bool_from_str(args.bootstrap),
                        "oob_score": bool_from_str(args.oob_score),
                        "class_weight": class_weight_val
                    }

                else:
                    raise ValueError(f"For classification, only 'logistic' or 'random_forest' models are supported. Got: {model_name}")

                # Compute sample weights for imbalance if requested and not using class_weight
                sample_weight = None
                if bool_from_str(args.enbalance) and model_name != "random_forest":
                    print("[INFO] Computing sample weights for imbalance")
                    try:
                        sample_weight = compute_sample_weight(class_weight='balanced', y=y_prepared)
                    except Exception as e:
                        print(f"[WARN] Could not compute sample weights: {e}")

                # cross-validation
                try:
                    cv_scoring = 'accuracy' if model_name == 'logistic' else 'roc_auc_ovr' if y_prepared.nunique() > 2 else 'roc_auc'
                    cv_scores = cross_val_score(clf, X, y_prepared, cv=5, scoring=cv_scoring)
                    metrics[f"cv_{cv_scoring}_mean"] = float(cv_scores.mean())
                    metrics[f"cv_{cv_scoring}_std"] = float(cv_scores.std())
                    print(f"[INFO] CV {cv_scoring}: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
                except Exception as e:
                    print(f"[WARN] CV failed: {e}")

                # fit model
                try:
                    if sample_weight is not None and model_name == "logistic":
                        clf.fit(X, y_prepared, sample_weight=sample_weight)
                    else:
                        clf.fit(X, y_prepared)
                except Exception as e:
                    print(f"[ERROR] Fit failed: {e}")
                    raise

                # predictions and metrics
                y_pred = clf.predict(X)
                y_pred_proba = clf.predict_proba(X) if hasattr(clf, "predict_proba") else None
                
                metrics.update({
                    "accuracy_train": float(accuracy_score(y_prepared, y_pred)),
                    "precision_train": float(precision_score(y_prepared, y_pred, average='weighted', zero_division=0)),
                    "recall_train": float(recall_score(y_prepared, y_pred, average='weighted', zero_division=0)),
                    "f1_train": float(f1_score(y_prepared, y_pred, average='weighted', zero_division=0)),
                    "model": model_name,
                    "balanced": bool_from_str(args.enbalance),
                    "label_info": map_info
                })
                
                # Add log loss if probabilities available
                if y_pred_proba is not None:
                    try:
                        metrics["log_loss_train"] = float(log_loss(y_prepared, y_pred_proba))
                    except Exception:
                        pass
                
                # Add ROC AUC for binary and multiclass
                if y_pred_proba is not None:
                    try:
                        if y_prepared.nunique() == 2:
                            metrics["roc_auc_train"] = float(roc_auc_score(y_prepared, y_pred_proba[:, 1]))
                        else:
                            metrics["roc_auc_ovr_train"] = float(roc_auc_score(y_prepared, y_pred_proba, multi_class='ovr', average='weighted'))
                    except Exception:
                        pass
                
                # Add OOB score for random forest if available
                if model_name == "random_forest" and bool_from_str(args.oob_score) and hasattr(clf, "oob_score_"):
                    metrics["oob_score"] = float(clf.oob_score_)
                    print(f"[INFO] OOB Score: {clf.oob_score_:.4f}")

                model_obj = clf

            elif task == "regression":
                print(f"[INFO] Regression task with model: {model_name}")
                
                y_num = pd.to_numeric(y, errors="coerce")
                valid_mask = y_num.notna()
                if not valid_mask.all():
                    dropped = int((~valid_mask).sum())
                    print(f"[WARN] Dropping {dropped} rows with non-numeric target")
                    X = X.loc[valid_mask].reset_index(drop=True)
                    y_num = y_num[valid_mask].reset_index(drop=True)

                if model_name == "linear":
                    print(f"[INFO] Training Linear Regression")
                    print(f"  - regularization: {args.regularization}")
                    print(f"  - C: {args.C_value}")
                    print(f"  - fit_intercept: {args.fit_intercept}")
                    print(f"  - max_iter: {args.max_iter}")
                    print(f"  - use_scaler: {args.use_scaler}")
                    
                    # Handle regularization
                    if args.regularization == "none":
                        reg = LinearRegression(fit_intercept=bool_from_str(args.fit_intercept))
                    elif args.regularization == "l2":
                        reg = Ridge(alpha=1.0/float(args.C_value) if float(args.C_value) > 0 else 1.0, 
                                  fit_intercept=bool_from_str(args.fit_intercept), 
                                  random_state=int(args.random_state),
                                  max_iter=int(args.max_iter))
                    elif args.regularization == "l1":
                        reg = Lasso(alpha=1.0/float(args.C_value) if float(args.C_value) > 0 else 1.0,
                                  fit_intercept=bool_from_str(args.fit_intercept),
                                  random_state=int(args.random_state),
                                  max_iter=int(args.max_iter))
                    elif args.regularization == "elasticnet":
                        reg = ElasticNet(alpha=1.0/float(args.C_value) if float(args.C_value) > 0 else 1.0,
                                       l1_ratio=0.5,
                                       fit_intercept=bool_from_str(args.fit_intercept),
                                       random_state=int(args.random_state),
                                       max_iter=int(args.max_iter))
                    else:
                        raise ValueError(f"Unknown regularization type: {args.regularization}")
                    
                    # Scale if requested
                    if bool_from_str(args.use_scaler):
                        reg = Pipeline([('scaler', StandardScaler()), ('est', reg)])
                    
                    model_config["params"] = {
                        "fit_intercept": bool_from_str(args.fit_intercept),
                        "regularization": args.regularization,
                        "C": float(args.C_value),
                        "max_iter": int(args.max_iter),
                        "use_scaler": bool_from_str(args.use_scaler)
                    }

                elif model_name == "polynomial":
                    print(f"[INFO] Training Polynomial Regression")
                    print(f"  - degree: {args.poly_degree}")
                    print(f"  - regularization: {args.regularization}")
                    print(f"  - C: {args.C_value}")
                    print(f"  - fit_intercept: {args.fit_intercept}")
                    print(f"  - max_iter: {args.max_iter}")
                    print(f"  - use_scaler: {args.use_scaler}")
                    
                    # Create polynomial features pipeline
                    poly_steps = [('poly', PolynomialFeatures(degree=int(args.poly_degree), include_bias=False))]
                    
                    # Add scaler if requested
                    if bool_from_str(args.use_scaler):
                        poly_steps.append(('scaler', StandardScaler()))
                    
                    # Add linear regression with optional regularization
                    if args.regularization == "none":
                        linear_model = LinearRegression(fit_intercept=bool_from_str(args.fit_intercept))
                    elif args.regularization == "l2":
                        linear_model = Ridge(alpha=1.0/float(args.C_value) if float(args.C_value) > 0 else 1.0,
                                           fit_intercept=bool_from_str(args.fit_intercept),
                                           random_state=int(args.random_state),
                                           max_iter=int(args.max_iter))
                    elif args.regularization == "l1":
                        linear_model = Lasso(alpha=1.0/float(args.C_value) if float(args.C_value) > 0 else 1.0,
                                           fit_intercept=bool_from_str(args.fit_intercept),
                                           random_state=int(args.random_state),
                                           max_iter=int(args.max_iter))
                    elif args.regularization == "elasticnet":
                        linear_model = ElasticNet(alpha=1.0/float(args.C_value) if float(args.C_value) > 0 else 1.0,
                                                l1_ratio=0.5,
                                                fit_intercept=bool_from_str(args.fit_intercept),
                                                random_state=int(args.random_state),
                                                max_iter=int(args.max_iter))
                    
                    poly_steps.append(('linear', linear_model))
                    reg = Pipeline(poly_steps)
                    
                    model_config["params"] = {
                        "degree": int(args.poly_degree),
                        "fit_intercept": bool_from_str(args.fit_intercept),
                        "regularization": args.regularization,
                        "C": float(args.C_value),
                        "max_iter": int(args.max_iter),
                        "use_scaler": bool_from_str(args.use_scaler)
                    }

                elif model_name == "random_forest":
                    print(f"[INFO] Training Random Forest Regressor")
                    print(f"  - n_estimators: {args.n_estimators}")
                    print(f"  - max_depth: {args.max_depth} (0 = unlimited)")
                    print(f"  - min_samples_split: {args.min_samples_split}")
                    print(f"  - min_samples_leaf: {args.min_samples_leaf}")
                    print(f"  - max_features: {args.max_features}")
                    print(f"  - bootstrap: {args.bootstrap}")
                    print(f"  - oob_score: {args.oob_score}")
                    
                    # Parse max_features
                    max_features_parsed = parse_max_features(args.max_features, X.shape[1])
                    
                    # Create Random Forest model
                    rf_model = RandomForestRegressor(
                        n_estimators=int(args.n_estimators),
                        max_depth=None if int(args.max_depth) <= 0 else int(args.max_depth),
                        min_samples_split=int(args.min_samples_split),
                        min_samples_leaf=int(args.min_samples_leaf),
                        max_features=max_features_parsed,
                        bootstrap=bool_from_str(args.bootstrap),
                        oob_score=bool_from_str(args.oob_score),
                        random_state=int(args.random_state),
                        n_jobs=-1
                    )
                    
                    reg = rf_model
                    model_config["params"] = {
                        "n_estimators": int(args.n_estimators),
                        "max_depth": None if int(args.max_depth) <= 0 else int(args.max_depth),
                        "min_samples_split": int(args.min_samples_split),
                        "min_samples_leaf": int(args.min_samples_leaf),
                        "max_features": max_features_parsed,
                        "bootstrap": bool_from_str(args.bootstrap),
                        "oob_score": bool_from_str(args.oob_score)
                    }

                else:
                    raise ValueError(f"For regression, only 'linear', 'polynomial' or 'random_forest' models are supported. Got: {model_name}")

                # cross-validation
                try:
                    cv_scores = cross_val_score(reg, X, y_num, cv=5, scoring='r2')
                    metrics["cv_r2_mean"] = float(cv_scores.mean())
                    metrics["cv_r2_std"] = float(cv_scores.std())
                    print(f"[INFO] CV R2: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")
                except Exception as e:
                    print(f"[WARN] CV failed: {e}")

                # fit model
                try:
                    reg.fit(X, y_num)
                except Exception as e:
                    print(f"[ERROR] Fit failed: {e}")
                    raise

                # predictions and metrics
                y_pred = reg.predict(X)
                metrics.update({
                    "r2_train": float(r2_score(y_num, y_pred)),
                    "rmse_train": float(np.sqrt(mean_squared_error(y_num, y_pred))),
                    "mae_train": float(mean_absolute_error(y_num, y_pred)),
                    "mse_train": float(mean_squared_error(y_num, y_pred)),
                    "model": model_name
                })
                
                # Add polynomial-specific info
                if model_name == "polynomial":
                    try:
                        if hasattr(reg, 'named_steps'):
                            poly_step = reg.named_steps.get('poly')
                            if poly_step:
                                n_features_in = poly_step.n_features_in_
                                n_features_out = poly_step.n_output_features_
                                metrics["poly_features_in"] = int(n_features_in)
                                metrics["poly_features_out"] = int(n_features_out)
                                print(f"[INFO] Polynomial features transformed: {n_features_in} -> {n_features_out}")
                    except Exception:
                        pass
                
                # Add OOB score for random forest if available
                if model_name == "random_forest" and bool_from_str(args.oob_score) and hasattr(reg, "oob_score_"):
                    metrics["oob_score"] = float(reg.oob_score_)
                    print(f"[INFO] OOB Score: {reg.oob_score_:.4f}")

                model_obj = reg

            else:
                raise ValueError(f"Unsupported task '{task}'. Must be 'classification' or 'regression'.")

            # finalize model_config
            model_config["trained_samples"] = int(len(X))
            model_config["trained_features"] = int(X.shape[1])
            
            # Add feature importance for random forest
            if model_name == "random_forest":
                try:
                    if task == "classification":
                        feature_importances = model_obj.feature_importances_
                    else:
                        feature_importances = model_obj.feature_importances_
                    
                    # Create feature importance dictionary
                    if isinstance(X, pd.DataFrame):
                        feature_names = X.columns.tolist()
                    else:
                        feature_names = [f"feature_{i}" for i in range(X.shape[1])]
                    
                    importance_dict = {}
                    for name, importance in zip(feature_names, feature_importances):
                        importance_dict[name] = float(importance)
                    
                    # Sort by importance
                    sorted_importance = dict(sorted(importance_dict.items(), key=lambda x: x[1], reverse=True))
                    metrics["top_5_features"] = list(sorted_importance.items())[:5]
                    
                except Exception as e:
                    print(f"[WARN] Could not extract feature importance: {e}")

            # save model, metrics and config
            ensure_dir_for(args.model_pickle)
            joblib.dump(model_obj, args.model_pickle)

            ensure_dir_for(args.metrics_json)
            with open(args.metrics_json, "w", encoding="utf-8") as f:
                json.dump(metrics, f, indent=2, ensure_ascii=False)

            ensure_dir_for(args.model_config)
            with open(args.model_config, "w", encoding="utf-8") as f:
                json.dump(model_config, f, indent=2, ensure_ascii=False)

            print("="*80)
            print("SUCCESS: Training completed")
            print("Model saved to:", args.model_pickle)
            print("Metrics saved to:", args.metrics_json)
            print("Model config saved to:", args.model_config)
            print("="*80)

        except Exception as e:
            print("="*80, file=sys.stderr)
            print("ERROR DURING TRAINING", file=sys.stderr)
            traceback.print_exc()
            print("="*80, file=sys.stderr)
            sys.exit(1)

    args:
      - --X_data
      - {inputPath: X_data}
      - --y_data
      - {inputPath: y_data}
      - --model_type
      - {inputValue: model_type}
      - --enbalance
      - {inputValue: enbalance}
      - --target_column
      - {inputValue: target_column}
      - --preprocess_metadata
      - {inputPath: preprocess_metadata}
      - --model_name
      - {inputValue: model_name}
      - --use_scaler
      - {inputValue: use_scaler}
      - --fit_intercept
      - {inputValue: fit_intercept}
      - --regularization
      - {inputValue: regularization}
      - --C_value
      - {inputValue: C_value}
      - --poly_degree
      - {inputValue: poly_degree}
      - --solver
      - {inputValue: solver}
      - --max_iter
      - {inputValue: max_iter}
      - --random_state
      - {inputValue: random_state}
      - --n_estimators
      - {inputValue: n_estimators}
      - --max_depth
      - {inputValue: max_depth}
      - --min_samples_split
      - {inputValue: min_samples_split}
      - --min_samples_leaf
      - {inputValue: min_samples_leaf}
      - --max_features
      - {inputValue: max_features}
      - --bootstrap
      - {inputValue: bootstrap}
      - --oob_score
      - {inputValue: oob_score}
      - --model_pickle
      - {outputPath: model_pickle}
      - --metrics_json
      - {outputPath: metrics_json}
      - --model_config
      - {outputPath: model_config}
